alphabet: "Nqwertyuiopasdfghjklzxcvbnm!,;.? "
train:
  lr: 1e-4
  batch_size: 8
  trainer: trainer_ljspeech
  use_guided_attention: True
  use_monotonic_attention: False
  seed: 42
  train_log_period: 50
  val_log_period: 20
  trainer_args:
    max_epochs: 20
    gpus: 1
    gradient_clip_val: 10
encoder:
  in_channels: 512
  cnn_layers: 3
  kernel_size: 5
  cnn_dropout: 0.5
  rnn_layers: 1
  hidden_size: 256
decoder:
  n_mel_channels: 80
  prenet_dim: 256
  prenet_layers: 5
  attention_rnn_dim: 1024
  decoder_rnn_dim: 1024
  encoder_embedding_dim: 512
  attention_dim: 128
  attention_location_n_filters: 32
  attention_location_kernel_size: 31
  teacher_forcing_ratio: 1.
  dropout_prob: 0.5
  zoneout_prob: 0.1
postnet:
  n_mel_channels: 80
  embedding_dim: 512
  kernel_size: 5
  num_layers: 5
  dropout_prob: 0.5
vocoder: waveglow
